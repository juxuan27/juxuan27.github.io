<html>
    <head>
        <link rel="stylesheet" type="text/css" href="assets/font-awesome-4.7.0/css/font-awesome.min.css">
        <link rel="stylesheet" type="text/css" href="assets/academicons-1.8.6/css/academicons.min.css">
        <link rel="stylesheet" type="text/css" href="assets/style.css">
        <link rel="icon" type="image/png" href="assets/figures/icon.png">
        <link rel="apple-touch-icon" type="image/png" href="assets/figures/icon.png">
        <title>Xuan Ju's Homepage </title>
    </head>
    
    <body><table border=0 width=1000px align=center><tr><td>
    
        <td valign="top">

        <br>
        <table style="font-size: 11pt;" border=0 width=100%>
            <tr>
                <td> 
                      <p style="text-align:left;font-size: 25pt;">
                        <name>Xuan Ju</name>
                      </p>
                      <p style="text-align:left;font-size: 13pt;">
                        <font> 
                            Ph.D. Candidate<br>
                            Computer Science and Engineering<br>
                            The Chinese University of Hong Kong<br><br>
                            <a style="font-size: 13pt" href="mailto:juxuan.27@gmail.com">E-mail</a> &nbsp/&nbsp
                            <a style="font-size: 13pt" href="assets/cv/CV_Xuan.pdf">CV</a> &nbsp/&nbsp
                            <a style="font-size: 13pt" href="https://scholar.google.com.hk/citations?user=pWzvK20AAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
                            <a style="font-size: 13pt" href="https://github.com/juxuan27"> Github </a> 
                        </font>
                      </p>
                </td>
                <td width = "20%">
                    <img src="assets/figures/avatar.jpg" style="width:210px; height:210px; border-radius:50%; ">
                        </td>
            </tr>
        </table> 

        
        <!-- <font face="helvetica, ariel, 'sans serif'">  -->
        <h2>Biography</h2>
        <p style="line-height:15pt; font-size: 13pt; text-align: justify; margin:10pt 0px">
          Hi, I'm Xuan Ju (鞠璇). 
          I am currently a second-year Ph.D. student in the <a href="https://cure-lab.github.io/">CURE Lab</a> at <a href="https://www.cuhk.edu.hk/chinese/index.html">The Chinese University of Hong Kong</a> guided by <a href="https://www.cse.cuhk.edu.hk/people/faculty/qiang-xu/">Pro. Qiang Xu</a>. 
          Before this, I majored in Computer Science and Technology (minored in Mathematics and Applied Mathematics) and got my bachelor's degree from Tongji University.
          <br>
          <br>
          I have a broad interest in most areas of computer vision, especially in image generation and human motion understanding. 
          Please do not hesitate to reach out to me via email at <a href="mailto:juxuan.27@gmail.com">juxuan.27@gmail.com</a> !
        </p>
        <!-- </font>        -->

        <!-- <h2>News</h2>
        <ul style="font-size: 14pt; text-align: justify;margin:10pt 0px"> 
        <li><strong>[11/2023]</strong> <font color="red" size="3"> I will intern at <a href="https://research.nvidia.com/labs/dir/">Deep Imagination Research group @ NVIDIA Research</a> next spring with <a href="https://mingyuliu.net/">Ming-Yu Liu</a>. See you in Santa Clara!</font> </li>
        <li><strong>[11/2023]</strong> <font color="red" size="3"> A high-quality 3D human generation framework <a href="https://alvinliu0.github.io/projects/HumanGaussian"><b>HumanGaussian</b></a> is released, with all the code and models available!</font> </li>
        <li><strong>[10/2023]</strong> <font color="black" size="3"> A hyper-realistic human generation foundation model <a href="https://snap-research.github.io/HyperHuman/"><b>HyperHuman</b></a> collaborated with Snap Research is on arXiv!</font> </li>
        <li><strong>[07/2023]</strong> <font color="black" size="3"> One paper is accepted to ICCV 2023. </font> </li>
        <li><strong>[07/2023]</strong> <font color="black" size="3"> One paper is accepted to MICCAI 2023. </font> </li>
        <li><strong>[05/2023]</strong> <font color="black" size="3"> Start my internship at Snap Research. See you in Los Angeles! </font> </li>
        <li><strong>[03/2023]</strong> <font color="black" size="3"> Two papers are accepted to CVPR 2023. </font> </li>
        <li><strong>[03/2023]</strong> <font color="black" size="3"> One paper is accepted to TMLR 2023. </font> </li>
        <li><strong>[09/2022]</strong> <font color="black" size="3"> One paper is accepted to NeurIPS 2022, with ANGIE accepted as Spotlight presentation!</font> </li>
        <li><strong>[07/2022]</strong> <font color="black" size="3"> Three papers are accepted to ECCV 2022, with SSP-NeRF accepted as Oral presentation!</font> </li>
        <li><strong>[03/2022]</strong> <font color="black" size="3"> One paper is accepted to CVPR 2022. </font> </li>
        <li><strong>[12/2021]</strong> <font color="black" size="3"> One paper is accepted to AAAI 2022. </font> </li>
        <li><strong>[12/2021]</strong> <font color="black" size="3"> One paper on molecule space manipulation accepted to MLDD Workshop on ICLR 2022 and ELLIS ML4Molecules 2021 with oral presentation. </font> </li>
        </ul>  -->

        <h2>Selected Publications</h2>
        <p style="margin:-20pt 0px">
          <br/>
          * equal contribution
          <table style="border-collapse:separate; border-spacing:0px 35px;" cellspacing="8">
          <tbody>

            
            <tr>
              <td width="30%">
                <img width="250" height="150" src="assets/figures/miradata.jpeg">
              </td>
              <td>
                <div class="title">
                  MiraData: A Large-Scale Video Dataset with Long Durations and Structured Captions
                </div>
                <div class="author">
                  <span class="me">Xuan Ju*</span>,
                  <a href="https://scholar.google.com/citations?user=uRCc-McAAAAJ&hl=zh-TW">Yiming Gao*</a>,
                  <a href="https://zzyfd.github.io/#/">Zhaoyang Zhang*</a>,
                  <a href="https://github.com/jiangyzy">Ziyang Yuan</a>,
                  <a href="https://xinntao.github.io/">Xiantao Wang</a>,
                  <a href="https://ailingzeng.site/">Ailing Zeng</a>,
                  <a href="http://xiongyu.me/">Yu Xiong</a>,
                  <a href="https://scholar.google.com/citations?user=eSiKPqUAAAAJ&hl=zh-CN">Qiang Xu</a>,
                  <a href="https://www.linkedin.com/in/yingshanprofile">Ying Shan</a>.
                </div>
                <div class="conf">
                  Under Review
                </div>
                <div>
                  <span class="tag"> <a href="https://mira-space.github.io/" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="" target="_blank">Paper</a> </span> /
                  <span class="tag"> <a href="" target="_blank">arXiv</a> </span> /
                  <span class="tag"> <a href="https://www.youtube.com/watch?v=3G0p7Jo3GYM" target="_blank">Video</a> </span> /
                  <span class="tag"> <a href="https://github.com/mira-space/MiraData" target="_blank">Code</a> </span> /
                  <span class="tag"> <a href="https://github.com/mira-space/MiraData" target="_blank">Data</a> </span>
                  <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/mira-space/MiraData">
                </div>
              </td>
            </tr>
            

            
            <tr>
              <td width="30%">
                <img width="250" height="150" src="assets/figures/brushnet.png">
              </td>
              <td>
                <div class="title">
                  BrushNet : A Plug-and-Play Image Inpainting Model with Decomposed Dual-Branch Diffusion
                </div>
                <div class="author">
                  <span class="me">Xuan Ju</span>,
                  <a href="https://alvinliu0.github.io/">Xian Liu</a>,
                  <a href="https://xinntao.github.io/">Xiantao Wang</a>,
                  <a href="https://yxbian23.github.io/">Yuxuan Bian</a>,
                  <a href="https://www.linkedin.com/in/yingshanprofile">Ying Shan</a>,
                  <a href="https://scholar.google.com/citations?user=eSiKPqUAAAAJ&hl=zh-CN">Qiang Xu</a>.
                </div>
                <div class="conf">
                  Under Review
                </div>
                <div>
                  <span class="tag"> <a href="https://tencentarc.github.io/BrushNet/" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/abs/2403.06976.pdf" target="_blank">Paper</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/abs/2403.06976" target="_blank">arXiv</a> </span> /
                  <span class="tag"> <a href="https://drive.google.com/file/d/1IkEBWcd2Fui2WHcckap4QFPcCI0gkHBh/view" target="_blank">Video</a> </span> /
                  <span class="tag"> <a href="https://github.com/TencentARC/BrushNet" target="_blank">Code</a> </span> /
                  <span class="tag"> <a href="https://forms.gle/9TgMZ8tm49UYsZ9s5" target="_blank">Data</a> </span>
                  <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/TencentARC/BrushNet">
                </div>
              </td>
            </tr>
            

            <tr>
              <td width="30%">
                <img width="250" height="150" src="assets/figures/directinversion.png">
              </td>
              <td>
                <div class="title">
                  Direct Inversion: Boosting Diffusion-based Editing with 3 Lines of Code
                </div>
                <div class="author">
                  <span class="me">Xuan Ju</span>,
                  <a href="https://ailingzeng.site/">Ailing Zeng</a>,
                  <a href="https://scholar.google.com/citations?user=HzemVzoAAAAJ&hl=zh-CN&oi=ao">Yuxuan Bian</a>,
                  <a href="https://www.shaotengliu.com/">Shaoteng Liu</a>,
                  <a href="https://scholar.google.com/citations?user=eSiKPqUAAAAJ&hl=zh-CN">Qiang Xu</a>.
                </div>
                <div class="conf">
                  International Conference on Learning Representations (<b>ICLR</b>), 2024
                </div>
                <div>
                  <span class="tag"> <a href="https://cure-lab.github.io/DirectInversion/" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/pdf/2310.01506.pdf" target="_blank">Paper</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/abs/2310.01506" target="_blank">arXiv</a> </span> /
                  <span class="tag"> <a href="https://drive.google.com/file/d/1HGr4ETPa7w-08KKOMhfxhngzQ9Y9Nj4H/view" target="_blank">Video</a> </span> /
                  <span class="tag"> <a href="https://github.com/cure-lab/DirectInversion" target="_blank">Code</a> </span> /
                  <span class="tag"> <a href="https://docs.google.com/forms/d/e/1FAIpQLSftGgDwLLMwrad9pX3Odbnd4UXGvcRuXDkRp6BT1nPk8fcH_g/viewform" target="_blank">Data</a> </span>
                  <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/cure-lab/DirectInversion">
                </div>
              </td>
            </tr>
            

            <tr>
              <td width="30%">
                <img width="250" height="150" src="assets/figures/humansd.png">
              </td>
              <td>
                <div class="title">
                  HumanSD: A Native Skeleton-Guided Diffusion Model for Human Image Generation
                </div>
                <div class="author">
                  <span class="me">Xuan Ju*</span>,
                  <a href="https://ailingzeng.site/">Ailing Zeng*</a>,
                  <a href="https://zcc31415926.github.io/">Chenchen Zhao*</a>,
                  <a href="https://scholar.google.com/citations?user=mt5mvZ8AAAAJ&hl=en">Jianan Wang</a>,
                  <a href="https://www.leizhang.org/">Lei Zhang</a>,
                  <a href="https://scholar.google.com/citations?user=eSiKPqUAAAAJ&hl=zh-CN">Qiang Xu</a>.
                </div>
                <div class="conf">
                  IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2023 <font color="red"> (Oral, Top 1.8%)</font>
                </div>
                <div>
                  <span class="tag"> <a href="https://idea-research.github.io/HumanSD/" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/pdf/2304.04269.pdf" target="_blank">Paper</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/abs/2304.04269" target="_blank">arXiv</a> </span> /
                  <span class="tag"> <a href="https://drive.google.com/file/d/1Djc2uJS5fmKnKeBnL34FnAAm3YSH20Bb/view" target="_blank">Video</a> </span> /
                  <span class="tag"> <a href="https://github.com/IDEA-Research/HumanSD" target="_blank">Code</a> </span> /
                  <span class="tag"> <a href="https://forms.gle/ANxDTjxcE2Ua45oU8" target="_blank">Data</a> </span>
                  <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/IDEA-Research/HumanSD">
                </div>
              </td>
            </tr>
            
            <tr>
              <td width="30%">
                <img width="250" height="150" src="assets/figures/humanart.png">
              </td>
              <td>
                <div class="title">
                  Human-Art: A Versatile Human-Centric Dataset Bridging Natural and Artificial Scenes
                </div>
                <div class="author">
                  <span class="me">Xuan Ju*</span>,
                  <a href="https://ailingzeng.site/">Ailing Zeng*</a>,
                  <a href="https://scholar.google.com/citations?user=mt5mvZ8AAAAJ&hl=en">Jianan Wang</a>,
                  <a href="https://scholar.google.com/citations?user=eSiKPqUAAAAJ&hl=zh-CN">Qiang Xu</a>,
                  <a href="https://www.leizhang.org/">Lei Zhang</a>.
                </div>
                <div class="conf">
                  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2023
                </div>
                <div>
                  <span class="tag"> <a href="https://idea-research.github.io/HumanArt/" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/pdf/2303.02760.pdf" target="_blank">Paper</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/abs/2303.02760" target="_blank">arXiv</a> </span> /
                  <span class="tag"> <a href="https://www.youtube.com/watch?v=djmTKVlw53E" target="_blank">Video</a> </span> /
                  <span class="tag"> <a href="https://github.com/IDEA-Research/HumanArt" target="_blank">Code</a> </span> /
                  <span class="tag"> <a href="https://forms.gle/UVv1GiNJNQsE4qif7" target="_blank">Data</a> </span>
                  <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/IDEA-Research/HumanArt">
                </div>
              </td>
            </tr>

            
            <tr>
              <td width="30%">
                <img width="250" height="150" src="assets/figures/aLLM4TS.webp">
              </td>
              <td>
                <div class="title">
                  Multi-Patch Prediction: Adapting LLMs for Time Series Representation Learning
                </div>
                <div class="author">
                  <a href="https://yxbian23.github.io/">Yuxuan Bian*</a>,
                  <span class="me">Xuan Ju*</span>,
                  <a href="https://www.jiangtongli.me/">Jiangtong Li*</a>,
                  <a href="https://scholar.google.com/citations?user=MjlxzxcAAAAJ&hl=zh-CN&oi=ao">Zhijian Xu</a>,
                  <a href="http://cs1.tongji.edu.cn/~dawei/">Dawei Cheng</a>,
                  <a href="https://scholar.google.com/citations?user=eSiKPqUAAAAJ&hl=zh-CN">Qiang Xu</a>.
                </div>
                <div class="conf">
                  International Conference on Machine Learning (<b>ICML</b>), 2024
                </div>
                <div>
                  <span class="tag"> <a href="https://arxiv.org/abs/2402.04852.pdf" target="_blank">Paper</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/abs/2402.04852" target="_blank">arXiv</a> </span> /
                </div>
              </td>
            </tr>
            

            <tr>
              <td width="30%">
                <img width="250" height="150" src="assets/figures/deciwatch.png">
              </td>
              <td>
                <div class="title">
                  Deciwatch: A simple baseline for 10x efficient 2d and 3d pose estimation
                </div>
                <div class="author"> 
                  <a href="https://ailingzeng.site/">Ailing Zeng</a>,
                  <span class="me">Xuan Ju</span>,
                  <a href="https://scholar.google.com.hk/citations?user=jZH2IPYAAAAJ&hl=en">Lei Yang</a>,
                  <a href="https://gaoruiyuan.com/">Ruiyuan Gao</a>,
                  <a href="https://scholar.google.com/citations?hl=en&user=02RXI00AAAAJ&view_op=list_works&sortby=pubdate">Xizhou Zhu</a>,
                  <a href="https://daibo.info/">Bo Dai</a>,
                  <a href="https://scholar.google.com/citations?user=eSiKPqUAAAAJ&hl=zh-CN">Qiang Xu</a>.
                </div>
                <div class="conf">
                  European Conference on Computer Vision (<b>ECCV</b>), 2022
                </div>
                <div>
                  <span class="tag"> <a href="https://ailingzeng.site/deciwatch" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/pdf/2203.08713.pdf" target="_blank">Paper</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/abs/2203.08713" target="_blank">arXiv</a> </span> /
                  <span class="tag"> <a href="https://github.com/cure-lab/DeciWatch" target="_blank">Code</a> </span> /
                  <span class="tag"> <a href="https://drive.google.com/drive/folders/1e5wEPWFNldihU5mBUpTOuQaGjgIxujrt" target="_blank">Data</a> </span>
                  <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/cure-lab/DeciWatch">
                </div>
              </td>
            </tr>

            <tr>
              <td width="30%">
                <img width="250" height="150" src="assets/figures/smoothnet.png">
              </td>
              <td>
                <div class="title">
                  Smoothnet: A plug-and-play network for refining human poses in videos
                </div>
                <div class="author">
                  <a href="https://ailingzeng.site/">Ailing Zeng</a>,
                  <a href="https://scholar.google.com.hk/citations?user=jZH2IPYAAAAJ&hl=en">Lei Yang</a>,
                  <span class="me">Xuan Ju</span>,
                  <a href="https://jeffli.site/">Jiefeng Li</a>,
                  <a href="https://iceclear.github.io/">Jianyi Wang</a>,
                  <a href="https://scholar.google.com/citations?user=eSiKPqUAAAAJ&hl=zh-CN">Qiang Xu</a>.
                </div>
                <div class="conf">
                  European Conference on Computer Vision (<b>ECCV</b>), 2022
                </div>
                <div>
                  <span class="tag"> <a href="https://ailingzeng.site/smoothnet" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/pdf/2112.13715.pdf" target="_blank">Paper</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/abs/2112.13715" target="_blank">arXiv</a> </span> /
                  <span class="tag"> <a href="https://www.youtube.com/watch?v=ijNUEmtxOLQ&t=34s" target="_blank">Video</a> </span> /
                  <span class="tag"> <a href="https://github.com/cure-lab/SmoothNet" target="_blank">Code</a> </span> /
                  <span class="tag"> <a href="https://drive.google.com/drive/folders/19Cu-_gqylFZAOTmHXzK52C80DKb0Tfx_" target="_blank">Data</a> </span>
                  <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/cure-lab/SmoothNet">
                </div>
              </td>
            </tr>

          </tbody>        
          </table>
        </p>

        <h2>Experiences</h2>
       
          <p style="margin:-20pt 0px">
          <table style="border-collapse:separate; border-spacing:10px 30px;" cellspacing="8">
          <tbody>

            <tr>
              <td width="33%">
                <img width="200" height="90" src="assets/figures/meta.png">
              </td>
              <td>
                <div class="title">
                  Research Intern, Meta GenAI
                </div>
                <div class="author">
                  Jul. 2024 - Dec. 2024
                </div>
                <div class="conf">
                  Topic: Video Generation
                </div>
                <div>
                  Supervised by: <a href="https://chihyaoma.github.io/">Kevin Chih-Yao Ma</a>
                </div>
              </td>
            </tr>

            <tr>
              <td width="33%">
                <img width="200" height="50" src="assets/figures/tencentarc.png">
              </td>
              <td>
                <div class="title">
                  Research Intern, Tencent ARC Laboratory
                </div>
                <div class="author">
                  Oct. 2023 - Jun. 2024
                </div>
                <div class="conf">
                  Topic: Image Inpainting, Video Generation
                </div>
                <div>
                  Supervised by: <a href="https://xinntao.github.io/">Xintao Wang</a>, <a href="https://scholar.google.com/citations?user=4oXBp9UAAAAJ">Ying Shan</a>
                </div>
              </td>
            </tr>

            <tr>
              <td width="23%">
                <img width="200" height="50" src="assets/figures/idea.jpeg">
              </td>
              <td>
                <div class="title">
                  Research Intern, International Digital Economy Academy (IDEA) CVR Laboratory
                </div>
                <div class="author">
                  Jun. 2022 - Oct. 2023
                </div>
                <div class="conf">
                  Topic: Human-Centric Image Generation
                </div>
                <div>
                  Supervised by: <a href="https://ailingzeng.site/">Ailing Zeng</a>, <a href="https://www.leizhang.org/">Lei Zhang</a></li>
                </div>
              </td>
            </tr>

            <tr>
              <td width="23%">
                <img width="200" height="50" src="assets/figures/sensetime.png">
              </td>
              <td>
                <div class="title">
                  Research Intern, X-Lab, SenseTime Research
                </div>
                <div class="author">
                  Dec. 2021 - May. 2022
                </div>
                <div class="conf">
                  Topic: Human Pose Estimation
                </div>
                <div>
                  Supervised by: <a href="https://scholar.google.com.hk/citations?user=jZH2IPYAAAAJ&hl=en">Lei Yang</a></li>
                </div>
              </td>
            </tr>

          </tbody>        
          </table>
        </p>

        <!-- <li><si> Research Intern, Creative Vision, Snap Research.</si>
        <br> May. 2023 - Sept. 2023
        <br> Topic: Human Generation Foundation Model.
        <br> Supervised by: <a href="https://alanspike.github.io/">Jian Ren</a>, <a href="https://aliaksandrsiarohin.github.io/aliaksandr-siarohin-website/">Aliaksandr Siarohin</a>, <a href="http://www.stulyakov.com/">Sergey Tulyakov</a>.</li>

        <li><si> Research Intern, Digital Content Group, Shanghai AI Laboratory.</si>
        <br> Jul. 2021 - Feb. 2022
        <br> Supervised by: <a href="http://daibo.info/">Bo Dai</a>.</li>
        <li>
        
        <si> Research Intern, Intelligent Video Group, SenseTime Research.</si>
        <br> Aug. 2020 - Jun. 2021
        <br> Supervised by: <a href="https://wywu.github.io/">Wayne Wu</a>.</li>
        </ul> -->

        <h2>Professional Services</h2>
        <!-- <font face="helvetica, ariel, 'sans serif'">  -->
          <ul style="font-size: 12pt; text-align: justify;">
          <li>Conference Reviewer for ECCV(2024), IJCV(2024), CVPR (2024), ICCV (2023), NeurIPS (2023)</li>
        </ul>
        <!-- </font> -->


        <h2>Selected Honors & Awards        </h2>
        <!-- <font face="helvetica, ariel, 'sans serif'">  -->
        <ul style="font-size: 12pt; text-align: justify;">
        <li> National Scholarship <div style="float:right; text-align:right">2020, 2021</div> </li>
        <li> Outstanding Graduate of Shanghai Province  <div style="float:right; text-align:right">2022</div> </li>
        <li> Qidi Scholarship <div style="float:right; text-align:right">2022</div> </li>
        <li> First Prize in "Challenge Cup" National College Students Contest  <div style="float:right; text-align:right">2022</div> </li>
        </ul>
        <!-- </font> -->

        <h2>Teaching Experience</h2>
        <!-- <font face="helvetica, ariel, 'sans serif'">  -->
          <ul style="font-size: 12pt; text-align: justify;">
          <!-- Teaching Assistant of the following courses in The Chinese University of Hong Kong:  -->
          <li>CSCI 1120, Introduction to Computing Using C++ <div style="float:right; text-align:right">Fall 2023</div></li>
          <li>CSCI 1520, Computer Principles and C++ Programming <div style="float:right; text-align:right">Spring 2022</div></li>
          <li>CSCI 1540, Fundamental Computing with C++ <div style="float:right; text-align:right">Fall 2022</div></li>
        </ul>
        <!-- </font> -->
      
        </body>


</html>
